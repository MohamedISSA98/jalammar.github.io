{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 2060', major=7, minor=5, total_memory=6143MB, multi_processor_count=30)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_properties('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (4.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: filelock in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from requests->transformers) (1.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/issa/miniconda3/envs/DL/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6920"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = df#[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apparently reassembled from the cutting room f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they presume their audience wo n't sit still f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a visually stunning rumination on love...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jonathan parker 's bartleby should have been t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  a stirring , funny and finally transporting re...  1\n",
       "1  apparently reassembled from the cutting room f...  0\n",
       "2  they presume their audience wo n't sit still f...  0\n",
       "3  this is a visually stunning rumination on love...  1\n",
       "4  jonathan parker 's bartleby should have been t...  1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppb.logging.set_verbosity_error()\n",
    "ppb.tokenization_utils_base._IS_PYTORCH_BACKEND = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = batch_1[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "#model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  67\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n",
      "Token IDs: tensor([  101,  1037, 18385,  1010,  6057,  1998,  2633, 18276,  2128, 16603,\n",
      "         1997,  5053,  1998,  1996,  6841,  1998,  5687,  5469,  3152,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(batch_1[1].values)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1037, 18385,  ...,     0,     0,     0],\n",
       "        [  101,  4593,  2128,  ...,     0,     0,     0],\n",
       "        [  101,  2027,  3653,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  1996,  5896,  ...,     0,     0,     0],\n",
       "        [  101,  1037,  5667,  ...,     0,     0,     0],\n",
       "        [  101,  1037, 12090,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,190 training samples\n",
      "1,730 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.75 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Our Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertForSequenceClassification: ['distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'pooler.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'pooler.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'classifier.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'classifier.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 3\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    325.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    325.    Elapsed: 0:00:28.\n",
      "  Batch   120  of    325.    Elapsed: 0:00:45.\n",
      "  Batch   160  of    325.    Elapsed: 0:00:58.\n",
      "  Batch   200  of    325.    Elapsed: 0:01:12.\n",
      "  Batch   240  of    325.    Elapsed: 0:01:26.\n",
      "  Batch   280  of    325.    Elapsed: 0:01:40.\n",
      "  Batch   320  of    325.    Elapsed: 0:01:53.\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epcoh took: 0:01:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.53\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    325.    Elapsed: 0:00:14.\n",
      "  Batch    80  of    325.    Elapsed: 0:00:27.\n",
      "  Batch   120  of    325.    Elapsed: 0:00:41.\n",
      "  Batch   160  of    325.    Elapsed: 0:00:55.\n",
      "  Batch   200  of    325.    Elapsed: 0:01:08.\n",
      "  Batch   240  of    325.    Elapsed: 0:01:22.\n",
      "  Batch   280  of    325.    Elapsed: 0:01:36.\n",
      "  Batch   320  of    325.    Elapsed: 0:01:50.\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:01:51\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "  Validation Loss: 0.57\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    325.    Elapsed: 0:00:14.\n",
      "  Batch    80  of    325.    Elapsed: 0:00:27.\n",
      "  Batch   120  of    325.    Elapsed: 0:00:41.\n",
      "  Batch   160  of    325.    Elapsed: 0:00:55.\n",
      "  Batch   200  of    325.    Elapsed: 0:01:08.\n",
      "  Batch   240  of    325.    Elapsed: 0:01:22.\n",
      "  Batch   280  of    325.    Elapsed: 0:01:36.\n",
      "  Batch   320  of    325.    Elapsed: 0:01:49.\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:51\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.75\n",
      "  Validation Loss: 0.55\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:05:55 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss, logits = outputs[0],outputs[1]\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            outputs = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            loss, logits = outputs[0], outputs[1]\n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.713769</td>\n",
       "      <td>0.692727</td>\n",
       "      <td>0.526376</td>\n",
       "      <td>0:01:55</td>\n",
       "      <td>0:00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.627774</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>0.696674</td>\n",
       "      <td>0:01:51</td>\n",
       "      <td>0:00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.551322</td>\n",
       "      <td>0.747133</td>\n",
       "      <td>0:01:51</td>\n",
       "      <td>0:00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1           0.713769     0.692727       0.526376       0:01:55         0:00:06\n",
       "2           0.627774     0.573921       0.696674       0:01:51         0:00:06\n",
       "3           0.463768     0.551322       0.747133       0:01:51         0:00:06"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "#pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mcuda()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5575161856"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.cuda' from '/home/issa/miniconda3/envs/DL/lib/python3.10/site-packages/torch/cuda/__init__.py'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 4            |        cudaMalloc retries: 4         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    4566 MB |    5360 MB |   19890 MB |   15323 MB |\\n|       from large pool |    4564 MB |    5358 MB |   19246 MB |   14682 MB |\\n|       from small pool |       2 MB |       3 MB |     643 MB |     641 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    4566 MB |    5360 MB |   19890 MB |   15323 MB |\\n|       from large pool |    4564 MB |    5358 MB |   19246 MB |   14682 MB |\\n|       from small pool |       2 MB |       3 MB |     643 MB |     641 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    4642 MB |    5430 MB |    5430 MB |     788 MB |\\n|       from large pool |    4638 MB |    5426 MB |    5426 MB |     788 MB |\\n|       from small pool |       4 MB |       4 MB |       4 MB |       0 MB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   77191 KB |  142606 KB |   16252 MB |   16177 MB |\\n|       from large pool |   75520 KB |  141056 KB |   15599 MB |   15525 MB |\\n|       from small pool |    1671 KB |    2065 KB |     653 MB |     651 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     931    |    1081    |    4268    |    3337    |\\n|       from large pool |     624    |     735    |    2813    |    2189    |\\n|       from small pool |     307    |     346    |    1455    |    1148    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     931    |    1081    |    4268    |    3337    |\\n|       from large pool |     624    |     735    |    2813    |    2189    |\\n|       from small pool |     307    |     346    |    1455    |    1148    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     216    |     253    |     253    |      37    |\\n|       from large pool |     214    |     251    |     251    |      37    |\\n|       from small pool |       2    |       2    |       2    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      39    |      47    |    2010    |    1971    |\\n|       from large pool |      29    |      40    |    1456    |    1427    |\\n|       from small pool |      10    |      11    |     554    |     544    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7293119430541992"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c22fa932e784be96db46eb151cfab5c71c9c2c585e77112cd8088a117bde26b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
